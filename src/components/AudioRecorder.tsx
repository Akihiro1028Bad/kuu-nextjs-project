"use client";

import { useState, useRef, useCallback, useEffect } from 'react';
import axios from 'axios';
import fixWebmDuration from 'webm-duration-fix';

interface AudioRecorderProps {
  onUploadSuccess: () => void;
}

export default function AudioRecorder({ onUploadSuccess }: AudioRecorderProps) {
  const [isRecording, setIsRecording] = useState(false);
  const [isPaused, setIsPaused] = useState(false);
  const [recordingTime, setRecordingTime] = useState(0);
  const [audioBlob, setAudioBlob] = useState<Blob | null>(null);
  const [audioUrl, setAudioUrl] = useState<string>('');
  const [isUploading, setIsUploading] = useState(false);
  const [uploadMessage, setUploadMessage] = useState('');
  const [soundName, setSoundName] = useState('');
  const [isSupported, setIsSupported] = useState<boolean | null>(null);
  const [volumeLevel, setVolumeLevel] = useState(0);

  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const streamRef = useRef<MediaStream | null>(null);
  const timerRef = useRef<NodeJS.Timeout | null>(null);
  const chunksRef = useRef<Blob[]>([]);
  const analyserRef = useRef<AnalyserNode | null>(null);
  const animationFrameRef = useRef<number | null>(null);

  const MAX_RECORDING_TIME = 30; // æœ€å¤§30ç§’

  // ãƒ–ãƒ©ã‚¦ã‚¶ã®éŒ²éŸ³æ©Ÿèƒ½ã‚µãƒãƒ¼ãƒˆãƒã‚§ãƒƒã‚¯
  useEffect(() => {
    const checkSupport = () => {
      const hasMediaDevices = !!(navigator.mediaDevices && navigator.mediaDevices.getUserMedia);
      const hasMediaRecorder = !!window.MediaRecorder;
      
      if (!hasMediaDevices) {
        setIsSupported(false);
        return;
      }
      
      if (!hasMediaRecorder) {
        setIsSupported(false);
        return;
      }

      // MediaRecorderã®ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹MIMEã‚¿ã‚¤ãƒ—ã‚’ãƒã‚§ãƒƒã‚¯
      const mimeTypes = [
        'audio/webm',
        'audio/webm;codecs=opus',
        'audio/ogg;codecs=opus',
        'audio/mp4',
        'audio/wav'
      ];
      
      const supportedType = mimeTypes.find(type => MediaRecorder.isTypeSupported(type));
      setIsSupported(!!supportedType);
    };

    checkSupport();

    // ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—é–¢æ•°
    return () => {
      if (timerRef.current) {
        clearInterval(timerRef.current);
      }
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current);
      }
      if (streamRef.current) {
        streamRef.current.getTracks().forEach(track => track.stop());
      }
      if (audioUrl) {
        URL.revokeObjectURL(audioUrl);
      }
    };
  }, [audioUrl]);

  // éŸ³é‡ãƒ¬ãƒ™ãƒ«ã‚’æ¸¬å®šã™ã‚‹é–¢æ•°
  const measureVolume = useCallback(() => {
    if (!analyserRef.current) return;
    const dataArray = new Uint8Array(analyserRef.current.fftSize);
    analyserRef.current.getByteTimeDomainData(dataArray);
    // ãƒ‡ãƒãƒƒã‚°: æ³¢å½¢ãƒ‡ãƒ¼ã‚¿ã®ä¸€éƒ¨ã‚’å‡ºåŠ›
    console.log('æ³¢å½¢ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«:', dataArray.slice(0, 16));
    let sum = 0;
    for (let i = 0; i < dataArray.length; i++) {
      const normalized = (dataArray[i] - 128) / 128;
      sum += normalized * normalized;
    }
    const rms = Math.sqrt(sum / dataArray.length); // Root Mean Squareï¼ˆå®ŸåŠ¹å€¤ï¼‰
    setVolumeLevel(rms * 100); // 0ã€œ100ã§è¡¨ç¤º
    if (isRecording) {
      animationFrameRef.current = requestAnimationFrame(measureVolume);
    }
  }, [isRecording]);

  // éŒ²éŸ³é–‹å§‹
  const startRecording = useCallback(async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      streamRef.current = stream;
      // ãƒ‡ãƒãƒƒã‚°: ãƒã‚¤ã‚¯ãƒ‡ãƒã‚¤ã‚¹æƒ…å ±
      if (navigator.mediaDevices.enumerateDevices) {
        const devices = await navigator.mediaDevices.enumerateDevices();
        console.log('åˆ©ç”¨å¯èƒ½ãªãƒ‡ãƒã‚¤ã‚¹:', devices);
      }
      // éŸ³é‡ãƒ¬ãƒ™ãƒ«æ¸¬å®šã®ãŸã‚ã®AudioContextè¨­å®š
      const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)();
      const source = audioContext.createMediaStreamSource(stream);
      const analyser = audioContext.createAnalyser();
      analyser.fftSize = 256;
      source.connect(analyser);
      analyserRef.current = analyser;
      console.log('AudioContext/Analyser/Sourceæ¥ç¶š:', { audioContext, source, analyser });
      
      // ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹MIMEã‚¿ã‚¤ãƒ—ã‚’å–å¾—
      const supportedType = 'audio/webm';
      if (!MediaRecorder.isTypeSupported(supportedType)) {
        alert('ã“ã®ãƒ–ãƒ©ã‚¦ã‚¶ã¯audio/webmã®éŒ²éŸ³ã«å¯¾å¿œã—ã¦ã„ã¾ã›ã‚“');
        setIsSupported(false);
        return;
      }
      
      const mediaRecorder = new MediaRecorder(stream, { mimeType: supportedType });
      mediaRecorderRef.current = mediaRecorder;
      chunksRef.current = [];

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          chunksRef.current.push(event.data);
        }
      };

      mediaRecorder.onstop = async () => {
        const blob = new Blob(chunksRef.current, { type: supportedType });
        // éŒ²éŸ³æ™‚é–“ã‚’å–å¾—
        const duration = recordingTime;
        // webm-duration-fixã§durationã‚’åŸ‹ã‚è¾¼ã‚€
        const fixedBlob = await fixWebmDuration(blob);

        // === ç„¡éŸ³ãƒˆãƒªãƒ å‡¦ç†ã‚’è¿½åŠ  ===
        // Blob â†’ ArrayBuffer â†’ AudioBuffer
        const arrayBuffer = await fixedBlob.arrayBuffer();
        // decodeAudioDataã¯ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯å½¢å¼ã ãŒã€Promiseãƒ©ãƒƒãƒ—ã§async/awaitå¯¾å¿œ
        function decodeAudioDataAsync(ctx: AudioContext, ab: ArrayBuffer): Promise<AudioBuffer> {
          return new Promise((resolve, reject) => {
            ctx.decodeAudioData(ab, resolve, reject);
          });
        }
        const audioBuffer = await decodeAudioDataAsync(audioContext, arrayBuffer.slice(0));

        // ç„¡éŸ³åˆ¤å®šç”¨ã®é–¾å€¤
        const SILENCE_THRESHOLD = 0.005; // 0.0ã€œ1.0ï¼ˆã‚ˆã‚Šå°ã•ãï¼‰
        const MIN_SILENCE_DURATION = 0.05; // 50msç›¸å½“
        const sampleRate = audioBuffer.sampleRate;
        const channelData = audioBuffer.getChannelData(0); // ãƒ¢ãƒãƒ©ãƒ«å‰æ
        const length = channelData.length;
        const minSilenceSamples = Math.floor(sampleRate * MIN_SILENCE_DURATION);

        // å‰æ–¹ã®ç„¡éŸ³åŒºé–“ã‚’æ¤œå‡º
        let startSample = 0;
        for (let i = 0; i < length; i++) {
          if (Math.abs(channelData[i]) > SILENCE_THRESHOLD) {
            // ç›´å‰ã¾ã§ç„¡éŸ³ãŒç¶šã„ã¦ã„ãŸå ´åˆã®ã¿
            startSample = Math.max(0, i - minSilenceSamples);
            break;
          }
        }
        // å¾Œæ–¹ã®ç„¡éŸ³åŒºé–“ã‚’æ¤œå‡º
        let endSample = length - 1;
        for (let i = length - 1; i >= 0; i--) {
          if (Math.abs(channelData[i]) > SILENCE_THRESHOLD) {
            endSample = Math.min(length - 1, i + minSilenceSamples);
            break;
          }
        }
        // åˆ‡ã‚Šå‡ºã—ç¯„å›²ãŒä¸æ­£ãªã‚‰å…¨ä½“ã‚’ä½¿ã†
        if (endSample <= startSample) {
          startSample = 0;
          endSample = length - 1;
        }
        const trimmedLength = endSample - startSample + 1;
        // æ–°ã—ã„AudioBufferã‚’ä½œæˆ
        const trimmedBuffer = audioContext.createBuffer(
          audioBuffer.numberOfChannels,
          trimmedLength,
          sampleRate
        );
        for (let ch = 0; ch < audioBuffer.numberOfChannels; ch++) {
          const src = audioBuffer.getChannelData(ch);
          const dst = trimmedBuffer.getChannelData(ch);
          for (let i = 0; i < trimmedLength; i++) {
            dst[i] = src[startSample + i];
          }
        }
        // AudioBuffer â†’ WAV Blob å¤‰æ›é–¢æ•°
        function audioBufferToWavBlob(buffer: AudioBuffer): Blob {
          // ç°¡æ˜“WAVã‚¨ãƒ³ã‚³ãƒ¼ãƒ€
          const numOfChan = buffer.numberOfChannels;
          const length = buffer.length * numOfChan * 2 + 44;
          const bufferArray = new ArrayBuffer(length);
          const view = new DataView(bufferArray);
          // RIFF identifier 'RIFF'
          writeString(view, 0, 'RIFF');
          view.setUint32(4, 36 + buffer.length * numOfChan * 2, true);
          writeString(view, 8, 'WAVE');
          // fmt chunk
          writeString(view, 12, 'fmt ');
          view.setUint32(16, 16, true); // chunk size
          view.setUint16(20, 1, true); // PCM
          view.setUint16(22, numOfChan, true);
          view.setUint32(24, buffer.sampleRate, true);
          view.setUint32(28, buffer.sampleRate * numOfChan * 2, true);
          view.setUint16(32, numOfChan * 2, true);
          view.setUint16(34, 16, true); // bits per sample
          // data chunk
          writeString(view, 36, 'data');
          view.setUint32(40, buffer.length * numOfChan * 2, true);
          // PCM samples
          let offset = 44;
          for (let i = 0; i < buffer.length; i++) {
            for (let ch = 0; ch < numOfChan; ch++) {
              let sample = buffer.getChannelData(ch)[i];
              sample = Math.max(-1, Math.min(1, sample));
              view.setInt16(offset, sample < 0 ? sample * 0x8000 : sample * 0x7FFF, true);
              offset += 2;
            }
          }
          return new Blob([bufferArray], { type: 'audio/wav' });
        }
        function writeString(view: DataView, offset: number, str: string) {
          for (let i = 0; i < str.length; i++) {
            view.setUint8(offset + i, str.charCodeAt(i));
          }
        }
        // ãƒˆãƒªãƒ å¾Œã®WAV Blobã‚’ç”Ÿæˆ
        const trimmedWavBlob = audioBufferToWavBlob(trimmedBuffer);
        setAudioBlob(trimmedWavBlob);
        const url = URL.createObjectURL(trimmedWavBlob);
        setAudioUrl(url);
        // éŸ³é‡æ¸¬å®šã‚’åœæ­¢
        if (animationFrameRef.current) {
          cancelAnimationFrame(animationFrameRef.current);
          animationFrameRef.current = null;
        }
        setVolumeLevel(0);
      };

      mediaRecorder.start();
      setIsRecording(true);
      setIsPaused(false);
      setRecordingTime(0);

      // éŒ²éŸ³æ™‚é–“ã®ã‚«ã‚¦ãƒ³ãƒˆ
      timerRef.current = setInterval(() => {
        setRecordingTime(prev => {
          const newTime = prev + 1;
          // æœ€å¤§éŒ²éŸ³æ™‚é–“ã«é”ã—ãŸã‚‰è‡ªå‹•åœæ­¢
          if (newTime >= MAX_RECORDING_TIME) {
            stopRecording();
            return prev;
          }
          return newTime;
        });
      }, 1000);

      // éŸ³é‡æ¸¬å®šé–‹å§‹
      measureVolume();

    } catch (error) {
      console.error('éŒ²éŸ³ã®é–‹å§‹ã«å¤±æ•—ã—ã¾ã—ãŸ:', error);
      alert('ãƒã‚¤ã‚¯ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ãŒè¨±å¯ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ãƒ–ãƒ©ã‚¦ã‚¶ã®è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚');
    }
  }, [measureVolume]);

  // éŒ²éŸ³åœæ­¢
  const stopRecording = useCallback(() => {
    if (mediaRecorderRef.current && isRecording) {
      mediaRecorderRef.current.stop();
      setIsRecording(false);
      setIsPaused(false);
      
      if (timerRef.current) {
        clearInterval(timerRef.current);
        timerRef.current = null;
      }

      // éŸ³é‡æ¸¬å®šã‚’åœæ­¢
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current);
        animationFrameRef.current = null;
      }
      setVolumeLevel(0);

      // ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’åœæ­¢
      if (streamRef.current) {
        streamRef.current.getTracks().forEach(track => track.stop());
        streamRef.current = null;
      }
    }
  }, [isRecording]);

  // éŒ²éŸ³ä¸€æ™‚åœæ­¢/å†é–‹
  const togglePause = useCallback(() => {
    if (!mediaRecorderRef.current) return;

    if (isPaused) {
      mediaRecorderRef.current.resume();
      setIsPaused(false);
      // ã‚¿ã‚¤ãƒãƒ¼å†é–‹
      timerRef.current = setInterval(() => {
        setRecordingTime(prev => {
          const newTime = prev + 1;
          if (newTime >= MAX_RECORDING_TIME) {
            stopRecording();
            return prev;
          }
          return newTime;
        });
      }, 1000);
      // éŸ³é‡æ¸¬å®šå†é–‹
      measureVolume();
    } else {
      mediaRecorderRef.current.pause();
      setIsPaused(true);
      // ã‚¿ã‚¤ãƒãƒ¼åœæ­¢
      if (timerRef.current) {
        clearInterval(timerRef.current);
        timerRef.current = null;
      }
      // éŸ³é‡æ¸¬å®šåœæ­¢
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current);
        animationFrameRef.current = null;
      }
    }
  }, [isPaused, measureVolume, stopRecording]);

  // éŒ²éŸ³ãƒªã‚»ãƒƒãƒˆ
  const resetRecording = useCallback(() => {
    stopRecording();
    setAudioBlob(null);
    setAudioUrl('');
    setRecordingTime(0);
    setSoundName('');
    setUploadMessage('');
  }, [stopRecording]);

  // æ™‚é–“ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
  const formatTime = (seconds: number) => {
    const mins = Math.floor(seconds / 60);
    const secs = seconds % 60;
    return `${mins.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`;
  };

  // ãƒ–ãƒ©ã‚¦ã‚¶ãŒã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„å ´åˆ
  if (isSupported === false) {
    return (
      <div className="p-4 bg-white rounded-lg shadow-sm border border-orange-200">
        <h4 className="text-lg font-semibold text-orange-800 mb-4">éŒ²éŸ³ã§éŸ³å£°ã‚’è¿½åŠ </h4>
        <div className="text-center py-8">
          <div className="text-red-500 text-4xl mb-4">ğŸ¤</div>
          <p className="text-orange-700 font-medium mb-2">éŒ²éŸ³æ©Ÿèƒ½ãŒã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã›ã‚“</p>
          <p className="text-sm text-orange-600">
            ãŠä½¿ã„ã®ãƒ–ãƒ©ã‚¦ã‚¶ã§ã¯éŒ²éŸ³æ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚<br />
            ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½ã‚’ã”åˆ©ç”¨ãã ã•ã„ã€‚
          </p>
        </div>
      </div>
    );
  }

  // ã‚µãƒãƒ¼ãƒˆãƒã‚§ãƒƒã‚¯ä¸­
  if (isSupported === null) {
    return (
      <div className="p-4 bg-white rounded-lg shadow-sm border border-orange-200">
        <h4 className="text-lg font-semibold text-orange-800 mb-4">éŒ²éŸ³ã§éŸ³å£°ã‚’è¿½åŠ </h4>
        <div className="text-center py-8">
          <div className="animate-spin rounded-full h-8 w-8 border-b-2 border-orange-500 mx-auto"></div>
          <p className="text-orange-600 mt-2">éŒ²éŸ³æ©Ÿèƒ½ã‚’ç¢ºèªä¸­...</p>
        </div>
      </div>
    );
  }

  return (
    <div className="p-4 bg-white rounded-lg shadow-sm border border-orange-200">
      <h4 className="text-lg font-semibold text-orange-800 mb-4">éŒ²éŸ³ã§éŸ³å£°ã‚’è¿½åŠ </h4>
      
      <div className="space-y-4">
        {/* éŒ²éŸ³ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ« */}
        <div className="flex items-center justify-center space-x-4">
          {!isRecording && !audioBlob && (
            <button
              onClick={startRecording}
              className="px-6 py-3 bg-red-500 text-white font-semibold rounded-full hover:bg-red-600 transition-colors flex items-center space-x-2"
            >
              <span className="w-3 h-3 bg-white rounded-full"></span>
              <span>éŒ²éŸ³é–‹å§‹</span>
            </button>
          )}

          {isRecording && (
            <>
              <button
                onClick={togglePause}
                className="px-4 py-2 bg-yellow-500 text-white font-semibold rounded-lg hover:bg-yellow-600 transition-colors"
              >
                {isPaused ? 'å†é–‹' : 'ä¸€æ™‚åœæ­¢'}
              </button>
              <button
                onClick={stopRecording}
                className="px-4 py-2 bg-gray-500 text-white font-semibold rounded-lg hover:bg-gray-600 transition-colors"
              >
                éŒ²éŸ³åœæ­¢
              </button>
            </>
          )}

          {audioBlob && (
            <button
              onClick={resetRecording}
              className="px-4 py-2 bg-gray-500 text-white font-semibold rounded-lg hover:bg-gray-600 transition-colors"
            >
              ã‚„ã‚Šç›´ã—
            </button>
          )}
        </div>

        {/* éŒ²éŸ³æ™‚é–“è¡¨ç¤º */}
        {isRecording && (
          <div className="text-center">
            <div className="text-2xl font-bold text-red-600">
              {formatTime(recordingTime)}
            </div>
            <div className="text-sm text-orange-600 mb-2">
              {isPaused ? 'ä¸€æ™‚åœæ­¢ä¸­' : 'éŒ²éŸ³ä¸­...'}
            </div>
            
            {/* æœ€å¤§éŒ²éŸ³æ™‚é–“ã®è¡¨ç¤º */}
            <div className="text-xs text-orange-500 mb-3">
              æœ€å¤§éŒ²éŸ³æ™‚é–“: {formatTime(MAX_RECORDING_TIME)}
            </div>
            
            {/* éŸ³é‡ãƒ¬ãƒ™ãƒ«è¡¨ç¤º */}
            <div className="w-full max-w-xs mx-auto">
              <div className="flex items-center space-x-2 mb-1">
                <span className="text-xs text-orange-600">éŸ³é‡:</span>
                <div className="flex-1 bg-orange-100 rounded-full h-2">
                  <div
                    className="h-2 rounded-full transition-all duration-100"
                    style={{
                      width: `${Math.min(100, (volumeLevel / 100) * 100)}%`,
                      background: 'linear-gradient(90deg, #f59e42 0%, #f97316 100%)'
                    }}
                  />
                </div>
              </div>
              <div className="text-xs text-orange-500">
                {volumeLevel > 0 ? 'ğŸ¤ éŸ³å£°ã‚’æ¤œå‡ºä¸­' : 'ğŸ”‡ éŸ³å£°ã‚’æ¤œå‡ºã—ã¦ã„ã¾ã›ã‚“'}
              </div>
            </div>
          </div>
        )}

        {/* éŒ²éŸ³ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ */}
        {audioUrl && (
          <div className="space-y-3">
            <h5 className="font-medium text-orange-800">éŒ²éŸ³ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼</h5>
            <audio
              controls
              src={audioUrl}
              className="w-full"
              onLoadedMetadata={e => console.log('duration:', e.currentTarget.duration)}
            />
            <div>
              <label className="block text-sm font-medium text-orange-700 mb-2">
                éŸ³å£°ã®åå‰
              </label>
              <input
                type="text"
                value={soundName}
                onChange={(e) => setSoundName(e.target.value)}
                placeholder="ä¾‹ï¼šç™’ã‚„ã—ã®ãã…ãƒ¼"
                className="w-full px-3 py-2 border border-orange-300 rounded-lg focus:outline-none focus:ring-2 focus:ring-orange-500"
              />
            </div>
            {/* ç™»éŒ²ï¼ˆä¿å­˜ï¼‰ãƒœã‚¿ãƒ³ã‚’å¾©æ´» */}
            <button
              onClick={async () => {
                if (!audioBlob || !soundName.trim()) return;
                setIsUploading(true);
                setUploadMessage('');
                try {
                  const formData = new FormData();
                  formData.append('file', audioBlob, `${soundName}.wav`);
                  formData.append('name', soundName);
                  await axios.post('/api/kuu/sounds', formData);
                  setUploadMessage('éŒ²éŸ³ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã—ãŸï¼');
                  resetRecording();
                  onUploadSuccess();
                } catch (error: any) {
                  setUploadMessage(error.response?.data?.message || 'ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ');
                } finally {
                  setIsUploading(false);
                }
              }}
              disabled={isUploading || !soundName.trim()}
              className="w-full px-4 py-2 bg-orange-500 text-white font-semibold rounded-lg hover:bg-orange-600 disabled:opacity-50 disabled:cursor-not-allowed transition-colors"
            >
              {isUploading ? 'ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­...' : 'éŒ²éŸ³ã‚’ç™»éŒ²'}
            </button>
            {uploadMessage && (
              <p className={`text-sm ${uploadMessage.includes('å¤±æ•—') ? 'text-red-600' : 'text-green-600'}`}>
                {uploadMessage}
              </p>
            )}
          </div>
        )}
      </div>
    </div>
  );
} 
"use client";

import { useState, useRef, useCallback, useEffect } from 'react';
import axios from 'axios';
import * as vad from '@ricky0123/vad-web';
import Modal from './Modal';

interface AudioRecorderProps {
  onUploadSuccess: () => void;
}

export default function AudioRecorder({ onUploadSuccess }: AudioRecorderProps) {
  const [isRecording, setIsRecording] = useState(false);
  const [isPaused, setIsPaused] = useState(false);
  const [recordingTime, setRecordingTime] = useState(0);
  const [audioBlob, setAudioBlob] = useState<Blob | null>(null);
  const [audioUrl, setAudioUrl] = useState<string>('');
  const [isUploading, setIsUploading] = useState(false);
  const [uploadMessage, setUploadMessage] = useState('');
  const [soundName, setSoundName] = useState('');
  const [isSupported, setIsSupported] = useState<boolean | null>(null);
  const [volumeLevel, setVolumeLevel] = useState(0);
  const [isVoiceDetected, setIsVoiceDetected] = useState(false);
  const [voiceDetectionStatus, setVoiceDetectionStatus] = useState<'idle' | 'loading' | 'ready' | 'error' | 'permission-denied'>('idle');
  
  // é€£ç¶šéŒ²éŸ³ç”¨ã®çŠ¶æ…‹
  const [isContinuousRecording, setIsContinuousRecording] = useState(false);
  const [audioSegments, setAudioSegments] = useState<Float32Array[]>([]);
  const [recordingStartTime, setRecordingStartTime] = useState<number | null>(null);
  
  // ãƒ¢ãƒ¼ãƒ€ãƒ«çŠ¶æ…‹
  const [showModal, setShowModal] = useState(false);
  const [modalTitle, setModalTitle] = useState('');
  const [modalMessage, setModalMessage] = useState('');
  const [modalType, setModalType] = useState<'success' | 'error' | 'info'>('info');

  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const streamRef = useRef<MediaStream | null>(null);
  const timerRef = useRef<NodeJS.Timeout | null>(null);
  const chunksRef = useRef<Blob[]>([]);
  const analyserRef = useRef<AnalyserNode | null>(null);
  const animationFrameRef = useRef<number | null>(null);
  const voiceDetectionRef = useRef<vad.MicVAD | null>(null);
  const audioContextRef = useRef<AudioContext | null>(null);

  const MAX_RECORDING_TIME = 30; // æœ€å¤§30ç§’

  // ãƒ¢ãƒ¼ãƒ€ãƒ«è¡¨ç¤ºç”¨ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
  const showSuccessModal = useCallback((title: string, message: string) => {
    setModalTitle(title);
    setModalMessage(message);
    setModalType('success');
    setShowModal(true);
  }, []);

  const closeModal = useCallback(() => {
    setShowModal(false);
  }, []);

  // Float32Arrayã‚’WAVãƒ•ã‚¡ã‚¤ãƒ«ã«å¤‰æ›ã™ã‚‹é–¢æ•°ï¼ˆä¿®æ­£ç‰ˆï¼‰
  const convertFloat32ArrayToWav = (audioData: Float32Array, sampleRate: number): Blob => {
    console.log('WAVå¤‰æ›é–‹å§‹:', { 
      audioDataLength: audioData.length, 
      sampleRate, 
      duration: audioData.length / sampleRate 
    });

    const numChannels = 1; // ãƒ¢ãƒãƒ©ãƒ«
    const bitsPerSample = 16;
    const bytesPerSample = bitsPerSample / 8;
    const blockAlign = numChannels * bytesPerSample;
    const byteRate = sampleRate * blockAlign;
    const dataSize = audioData.length * bytesPerSample;
    const fileSize = 36 + dataSize;

    console.log('WAVãƒ˜ãƒƒãƒ€ãƒ¼æƒ…å ±:', {
      dataSize,
      fileSize,
      byteRate,
      blockAlign
    });

    const buffer = new ArrayBuffer(44 + dataSize);
    const view = new DataView(buffer);

    // WAVãƒ˜ãƒƒãƒ€ãƒ¼ï¼ˆä¿®æ­£ç‰ˆï¼‰
    // RIFF identifier
    view.setUint8(0, 0x52); // R
    view.setUint8(1, 0x49); // I
    view.setUint8(2, 0x46); // F
    view.setUint8(3, 0x46); // F

    // File size (little endian)
    view.setUint32(4, fileSize, true);

    // WAVE identifier
    view.setUint8(8, 0x57); // W
    view.setUint8(9, 0x41); // A
    view.setUint8(10, 0x56); // V
    view.setUint8(11, 0x45); // E

    // fmt chunk
    view.setUint8(12, 0x66); // f
    view.setUint8(13, 0x6D); // m
    view.setUint8(14, 0x74); // t
    view.setUint8(15, 0x20); // space

    // fmt chunk size (16 for PCM)
    view.setUint32(16, 16, true);

    // Audio format (1 for PCM)
    view.setUint16(20, 1, true);

    // Number of channels
    view.setUint16(22, numChannels, true);

    // Sample rate
    view.setUint32(24, sampleRate, true);

    // Byte rate
    view.setUint32(28, byteRate, true);

    // Block align
    view.setUint16(32, blockAlign, true);

    // Bits per sample
    view.setUint16(34, bitsPerSample, true);

    // data chunk
    view.setUint8(36, 0x64); // d
    view.setUint8(37, 0x61); // a
    view.setUint8(38, 0x74); // t
    view.setUint8(39, 0x61); // a

    // data chunk size
    view.setUint32(40, dataSize, true);

    // Audio data
    let offset = 44;
    let maxSample = 0;
    let minSample = 0;
    
    for (let i = 0; i < audioData.length; i++) {
      const sample = Math.max(-1, Math.min(1, audioData[i]));
      const intSample = sample < 0 ? sample * 0x8000 : sample * 0x7FFF;
      view.setInt16(offset, intSample, true);
      offset += 2;
      
      // ãƒ‡ãƒãƒƒã‚°ç”¨ï¼šæœ€å¤§ãƒ»æœ€å°å€¤ã‚’è¨˜éŒ²
      if (sample > maxSample) maxSample = sample;
      if (sample < minSample) minSample = sample;
    }

    console.log('WAVå¤‰æ›å®Œäº†:', {
      maxSample,
      minSample,
      bufferSize: buffer.byteLength,
      expectedSize: 44 + dataSize
    });

    return new Blob([buffer], { type: 'audio/wav' });
  };

  // ä»£æ›¿ã®éŸ³å£°å¤‰æ›é–¢æ•°ï¼ˆWebMå½¢å¼ï¼‰
  const convertFloat32ArrayToWebM = async (audioData: Float32Array, sampleRate: number): Promise<Blob> => {
    console.log('WebMå¤‰æ›é–‹å§‹');
    
    try {
      // AudioContextã‚’ä½œæˆ
      const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)();
      
      // Float32Arrayã‚’AudioBufferã«å¤‰æ›
      const audioBuffer = audioContext.createBuffer(1, audioData.length, sampleRate);
      audioBuffer.getChannelData(0).set(audioData);
      
      // AudioBufferã‚’Blobã«å¤‰æ›
      const mediaStreamDestination = audioContext.createMediaStreamDestination();
      const source = audioContext.createBufferSource();
      source.buffer = audioBuffer;
      source.connect(mediaStreamDestination);
      source.start();
      
      // MediaRecorderã§WebMã«å¤‰æ›
      const mediaRecorder = new MediaRecorder(mediaStreamDestination.stream, {
        mimeType: 'audio/webm;codecs=opus'
      });
      
      const chunks: Blob[] = [];
      
      return new Promise((resolve, reject) => {
        mediaRecorder.ondataavailable = (event) => {
          if (event.data.size > 0) {
            chunks.push(event.data);
          }
        };
        
        mediaRecorder.onstop = () => {
          const blob = new Blob(chunks, { type: 'audio/webm' });
          console.log('WebMå¤‰æ›å®Œäº†:', { size: blob.size });
          resolve(blob);
        };
        
        mediaRecorder.onerror = reject;
        
        mediaRecorder.start();
        setTimeout(() => {
          mediaRecorder.stop();
          audioContext.close();
        }, 100);
      });
    } catch (error) {
      console.error('WebMå¤‰æ›ã‚¨ãƒ©ãƒ¼:', error);
      throw error;
    }
  };

  // éŸ³å£°ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’çµåˆã™ã‚‹é–¢æ•°
  const combineAudioSegments = (segments: Float32Array[]): Float32Array => {
    if (segments.length === 0) return new Float32Array(0);
    if (segments.length === 1) return segments[0];
    
    // å…¨ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®åˆè¨ˆé•·ã‚’è¨ˆç®—
    const totalLength = segments.reduce((sum, segment) => sum + segment.length, 0);
    const combined = new Float32Array(totalLength);
    
    let offset = 0;
    for (const segment of segments) {
      combined.set(segment, offset);
      offset += segment.length;
    }
    
    return combined;
  };

  // é€£ç¶šéŒ²éŸ³ã‚’é–‹å§‹ã™ã‚‹é–¢æ•°
  const startContinuousRecording = useCallback(() => {
    setIsContinuousRecording(true);
    setAudioSegments([]);
    setRecordingStartTime(Date.now());
    console.log('é€£ç¶šéŒ²éŸ³é–‹å§‹');
  }, []);

  // é€£ç¶šéŒ²éŸ³ã‚’åœæ­¢ã™ã‚‹é–¢æ•°
  const stopContinuousRecording = useCallback(async () => {
    if (!isContinuousRecording || audioSegments.length === 0) {
      setIsContinuousRecording(false);
      setAudioSegments([]);
      setRecordingStartTime(null);
      return;
    }
    
    console.log(`é€£ç¶šéŒ²éŸ³åœæ­¢: ${audioSegments.length}ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ`);
    
    // ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’çµåˆ
    const combinedAudio = combineAudioSegments(audioSegments);
    console.log('çµåˆå¾Œã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿:', {
      length: combinedAudio.length,
      duration: combinedAudio.length / 16000,
      segments: audioSegments.length
    });
    
    // çµåˆã—ãŸéŸ³å£°ã‚’å‡¦ç†
    try {
      console.log('WAVå½¢å¼ã§å¤‰æ›ã‚’è©¦è¡Œ...');
      const wavBlob = convertFloat32ArrayToWav(combinedAudio, 16000);
      
      console.log('WAV Blobè©³ç´°:', {
        size: wavBlob.size,
        type: wavBlob.type
      });

      setAudioBlob(wavBlob);
      setAudioUrl(URL.createObjectURL(wavBlob));
      console.log('é€£ç¶šéŒ²éŸ³å®Œäº†:', combinedAudio.length, 'ã‚µãƒ³ãƒ—ãƒ«');
      
    } catch (wavError) {
      console.error('WAVå¤‰æ›ã‚¨ãƒ©ãƒ¼:', wavError);
      
      try {
        console.log('WebMå½¢å¼ã§å¤‰æ›ã‚’è©¦è¡Œ...');
        const webmBlob = await convertFloat32ArrayToWebM(combinedAudio, 16000);
        
        console.log('WebM Blobè©³ç´°:', {
          size: webmBlob.size,
          type: webmBlob.type
        });

        setAudioBlob(webmBlob);
        setAudioUrl(URL.createObjectURL(webmBlob));
        console.log('é€£ç¶šéŒ²éŸ³å®Œäº†ï¼ˆWebMï¼‰:', combinedAudio.length, 'ã‚µãƒ³ãƒ—ãƒ«');
        
      } catch (webmError) {
        console.error('WebMå¤‰æ›ã‚¨ãƒ©ãƒ¼:', webmError);
        
        console.log('ç”Ÿãƒ‡ãƒ¼ã‚¿å½¢å¼ã§ä¿å­˜...');
        const fallbackBlob = new Blob([combinedAudio], { type: 'audio/raw' });
        setAudioBlob(fallbackBlob);
        setAudioUrl(URL.createObjectURL(fallbackBlob));
        console.log('é€£ç¶šéŒ²éŸ³å®Œäº†ï¼ˆç”Ÿãƒ‡ãƒ¼ã‚¿ï¼‰:', combinedAudio.length, 'ã‚µãƒ³ãƒ—ãƒ«');
      }
    }
    
    // çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
    setIsContinuousRecording(false);
    setAudioSegments([]);
    setRecordingStartTime(null);
  }, [isContinuousRecording, audioSegments, convertFloat32ArrayToWav, convertFloat32ArrayToWebM]);

  // ãƒã‚¤ã‚¯æ¨©é™ã‚’ãƒã‚§ãƒƒã‚¯ã™ã‚‹é–¢æ•°
  const checkMicrophonePermission = async (): Promise<boolean> => {
    try {
      // æ—¢å­˜ã®æ¨©é™ã‚’ãƒã‚§ãƒƒã‚¯
      const permission = await navigator.permissions.query({ name: 'microphone' as PermissionName });
      
      if (permission.state === 'granted') {
        return true;
      } else if (permission.state === 'denied') {
        return false;
      } else {
        // æ¨©é™ãŒæœªè¨­å®šã®å ´åˆã¯ã€ä¸€æ™‚çš„ã«ãƒã‚¤ã‚¯ã«ã‚¢ã‚¯ã‚»ã‚¹ã—ã¦æ¨©é™ã‚’è¦æ±‚
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        stream.getTracks().forEach(track => track.stop());
        return true;
      }
    } catch (error) {
      console.error('ãƒã‚¤ã‚¯æ¨©é™ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼:', error);
      return false;
    }
  };

  // è‡ªå‹•éŸ³å£°æ¤œå‡ºã®åˆæœŸåŒ–ï¼ˆåŸºæœ¬è¨­å®šï¼‰
  useEffect(() => {
    const initVoiceDetection = async () => {
      try {
        setVoiceDetectionStatus('loading');
        
        // ãƒã‚¤ã‚¯æ¨©é™ã‚’ãƒã‚§ãƒƒã‚¯
        const hasPermission = await checkMicrophonePermission();
        if (!hasPermission) {
          setVoiceDetectionStatus('permission-denied');
          return;
        }
        
        // è‡ªå‹•éŸ³å£°æ¤œå‡ºã®åˆæœŸåŒ–ï¼ˆã‚ˆã‚Šå®‰å®šã—ãŸè¨­å®šï¼‰
        voiceDetectionRef.current = await vad.MicVAD.new({
          onSpeechStart: () => {
            console.log('éŸ³å£°æ¤œå‡ºé–‹å§‹');
            setIsVoiceDetected(true);
          },
          onSpeechEnd: async (audio) => {
            console.log('éŸ³å£°æ¤œå‡ºçµ‚äº†');
            setIsVoiceDetected(false);
            
            // éŸ³å£°ãŒæ¤œå‡ºã•ã‚ŒãŸå ´åˆã®ã¿éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
            if (audio && audio.length > 0) {
              console.log('VADéŸ³å£°ãƒ‡ãƒ¼ã‚¿è©³ç´°:', {
                length: audio.length,
                type: audio.constructor.name,
                sampleRate: 16000,
                duration: audio.length / 16000,
                firstFewSamples: Array.from(audio.slice(0, 10)),
                lastFewSamples: Array.from(audio.slice(-10))
              });

              // é€£ç¶šéŒ²éŸ³ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã¯ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¨ã—ã¦ä¿å­˜
              if (isContinuousRecording) {
                console.log('é€£ç¶šéŒ²éŸ³ã‚»ã‚°ãƒ¡ãƒ³ãƒˆè¿½åŠ :', audio.length, 'ã‚µãƒ³ãƒ—ãƒ«');
                setAudioSegments(prev => [...prev, audio]);
                return;
              }

              // å˜ç™ºéŒ²éŸ³ãƒ¢ãƒ¼ãƒ‰ï¼ˆå¾“æ¥ã®å‡¦ç†ï¼‰
              const minDuration = 0.5; // ç§’ï¼ˆçŸ­ã„éŸ³å£°ã‚‚å–å¾—ï¼‰
              const minSamples = minDuration * 16000; // ã‚µãƒ³ãƒ—ãƒ«æ•°
              
              if (audio.length >= minSamples) {
                try {
                  // ã¾ãšWAVå½¢å¼ã‚’è©¦ã™
                  console.log('WAVå½¢å¼ã§å¤‰æ›ã‚’è©¦è¡Œ...');
                  const wavBlob = convertFloat32ArrayToWav(audio, 16000);
                  
                  console.log('WAV Blobè©³ç´°:', {
                    size: wavBlob.size,
                    type: wavBlob.type
                  });

                  setAudioBlob(wavBlob);
                  setAudioUrl(URL.createObjectURL(wavBlob));
                  console.log('WAVå½¢å¼ã§éŸ³å£°éŒ²éŸ³å®Œäº†:', audio.length, 'ã‚µãƒ³ãƒ—ãƒ«');
                  
                } catch (wavError) {
                  console.error('WAVå¤‰æ›ã‚¨ãƒ©ãƒ¼:', wavError);
                  
                  // WAVãŒå¤±æ•—ã—ãŸå ´åˆã¯WebMå½¢å¼ã‚’è©¦ã™
                  try {
                    console.log('WebMå½¢å¼ã§å¤‰æ›ã‚’è©¦è¡Œ...');
                    const webmBlob = await convertFloat32ArrayToWebM(audio, 16000);
                    
                    console.log('WebM Blobè©³ç´°:', {
                      size: webmBlob.size,
                      type: webmBlob.type
                    });

                    setAudioBlob(webmBlob);
                    setAudioUrl(URL.createObjectURL(webmBlob));
                    console.log('WebMå½¢å¼ã§éŸ³å£°éŒ²éŸ³å®Œäº†:', audio.length, 'ã‚µãƒ³ãƒ—ãƒ«');
                    
                  } catch (webmError) {
                    console.error('WebMå¤‰æ›ã‚¨ãƒ©ãƒ¼:', webmError);
                    
                    // æœ€å¾Œã®æ‰‹æ®µï¼šç”Ÿãƒ‡ãƒ¼ã‚¿ã‚’Blobã¨ã—ã¦ä¿å­˜
                    console.log('ç”Ÿãƒ‡ãƒ¼ã‚¿å½¢å¼ã§ä¿å­˜...');
                    const fallbackBlob = new Blob([audio], { type: 'audio/raw' });
                    setAudioBlob(fallbackBlob);
                    setAudioUrl(URL.createObjectURL(fallbackBlob));
                    console.log('ç”Ÿãƒ‡ãƒ¼ã‚¿å½¢å¼ã§éŸ³å£°éŒ²éŸ³å®Œäº†:', audio.length, 'ã‚µãƒ³ãƒ—ãƒ«');
                  }
                }
              } else {
                console.log('éŸ³å£°ãŒçŸ­ã™ãã¾ã™:', audio.length, 'ã‚µãƒ³ãƒ—ãƒ«');
              }
            }
          },
          onVADMisfire: () => {
            console.log('VADèª¤æ¤œå‡º');
            setIsVoiceDetected(false);
          },
          onFrameProcessed: (probabilities, frame) => {
            // ãƒ•ãƒ¬ãƒ¼ãƒ å‡¦ç†ã®ãƒ­ã‚°ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
            console.log('VADç¢ºç‡:', probabilities);
          },
          // VADã®æ„Ÿåº¦ã‚’èª¿æ•´ï¼ˆé€£ç¶šéŒ²éŸ³å¯¾å¿œï¼‰
          minSpeechFrames: 3, // æœ€å°éŸ³å£°ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ï¼ˆé€£ç¶šéŒ²éŸ³ã§ã¯çŸ­ã‚ã«ï¼‰
          frameSamples: 1024, // ãƒ•ãƒ¬ãƒ¼ãƒ ã‚ãŸã‚Šã®ã‚µãƒ³ãƒ—ãƒ«æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1024ï¼‰
          positiveSpeechThreshold: 0.5, // éŸ³å£°åˆ¤å®šã®é–¾å€¤ï¼ˆé€£ç¶šéŒ²éŸ³ã§ã¯ä½ã‚ã«ï¼‰
          negativeSpeechThreshold: 0.2, // ééŸ³å£°åˆ¤å®šã®é–¾å€¤ï¼ˆé€£ç¶šéŒ²éŸ³ã§ã¯ä½ã‚ã«ï¼‰
          redemptionFrames: 8, // èª¤æ¤œå‡ºä¿®æ­£ãƒ•ãƒ¬ãƒ¼ãƒ æ•°ï¼ˆé€£ç¶šéŒ²éŸ³ã§ã¯çŸ­ã‚ã«ï¼‰
          preSpeechPadFrames: 1 // éŸ³å£°é–‹å§‹å‰ã®ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆé€£ç¶šéŒ²éŸ³ã§ã¯å°‘ãªã‚ã«ï¼‰
        });

        setVoiceDetectionStatus('ready');
        console.log('è‡ªå‹•éŸ³å£°æ¤œå‡ºåˆæœŸåŒ–å®Œäº†');
      } catch (error) {
        console.error('è‡ªå‹•éŸ³å£°æ¤œå‡ºåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼:', error);
        
        // æ¨©é™ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯ç‰¹åˆ¥ãªå‡¦ç†
        if (error instanceof Error && error.name === 'NotAllowedError') {
          setVoiceDetectionStatus('permission-denied');
        } else {
          setVoiceDetectionStatus('error');
        }
      }
    };

    initVoiceDetection();

    return () => {
      if (voiceDetectionRef.current) {
        try {
          voiceDetectionRef.current.destroy();
        } catch (error) {
          console.error('è‡ªå‹•éŸ³å£°æ¤œå‡ºç ´æ£„ã‚¨ãƒ©ãƒ¼:', error);
        }
      }
    };
  }, []);



  // ãƒ–ãƒ©ã‚¦ã‚¶ã®éŒ²éŸ³æ©Ÿèƒ½ã‚µãƒãƒ¼ãƒˆãƒã‚§ãƒƒã‚¯
  useEffect(() => {
    const checkSupport = () => {
      const hasMediaDevices = !!(navigator.mediaDevices && navigator.mediaDevices.getUserMedia);
      const hasMediaRecorder = !!window.MediaRecorder;
      
      if (!hasMediaDevices) {
        setIsSupported(false);
        return;
      }
      
      if (!hasMediaRecorder) {
        setIsSupported(false);
        return;
      }

      // MediaRecorderã®ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹MIMEã‚¿ã‚¤ãƒ—ã‚’ãƒã‚§ãƒƒã‚¯
      const mimeTypes = [
        'audio/webm',
        'audio/webm;codecs=opus',
        'audio/ogg;codecs=opus',
        'audio/mp4',
        'audio/wav'
      ];
      
      const supportedType = mimeTypes.find(type => MediaRecorder.isTypeSupported(type));
      setIsSupported(!!supportedType);
    };

    checkSupport();

    // ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—é–¢æ•°
    return () => {
      if (timerRef.current) {
        clearInterval(timerRef.current);
      }
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current);
      }
      if (streamRef.current) {
        streamRef.current.getTracks().forEach(track => track.stop());
      }
      if (audioUrl) {
        URL.revokeObjectURL(audioUrl);
      }
      if (audioContextRef.current && audioContextRef.current.state !== 'closed') {
        try {
          audioContextRef.current.close();
        } catch (error) {
          console.error('AudioContexté–‰ã˜ã‚‹ã‚¨ãƒ©ãƒ¼:', error);
        }
      }
    };
  }, [audioUrl]);

  // éŸ³é‡ãƒ¬ãƒ™ãƒ«ã‚’æ¸¬å®šã™ã‚‹é–¢æ•°
  const measureVolume = useCallback(() => {
    if (!analyserRef.current) return;
    const dataArray = new Uint8Array(analyserRef.current.fftSize);
    analyserRef.current.getByteTimeDomainData(dataArray);
    
    let sum = 0;
    for (let i = 0; i < dataArray.length; i++) {
      const normalized = (dataArray[i] - 128) / 128;
      sum += normalized * normalized;
    }
    const rms = Math.sqrt(sum / dataArray.length);
    setVolumeLevel(rms * 100);
    
    if (isRecording) {
      animationFrameRef.current = requestAnimationFrame(measureVolume);
    }
  }, [isRecording]);

  // æ¨©é™ã‚’å†è¦æ±‚ã™ã‚‹é–¢æ•°
  const requestMicrophonePermission = async (): Promise<boolean> => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      stream.getTracks().forEach(track => track.stop());
      return true;
    } catch (error) {
      console.error('ãƒã‚¤ã‚¯æ¨©é™è¦æ±‚ã‚¨ãƒ©ãƒ¼:', error);
      return false;
    }
  };

  // è‡ªå‹•éŸ³å£°æ¤œå‡ºéŒ²éŸ³é–‹å§‹
  const startRecording = useCallback(async () => {
    // é€£ç¶šéŒ²éŸ³ãƒ¢ãƒ¼ãƒ‰ã‚’é–‹å§‹
    startContinuousRecording();
    
    try {
      if (voiceDetectionStatus === 'permission-denied') {
        const granted = await requestMicrophonePermission();
        if (granted) {
          // æ¨©é™ãŒè¨±å¯ã•ã‚ŒãŸå ´åˆã¯åˆæœŸåŒ–ã‚’å†å®Ÿè¡Œ
          setVoiceDetectionStatus('loading');
          const hasPermission = await checkMicrophonePermission();
          if (hasPermission) {
            // VADã‚’å†åˆæœŸåŒ–
            try {
              voiceDetectionRef.current = await vad.MicVAD.new({
                onSpeechStart: () => {
                  console.log('éŸ³å£°æ¤œå‡ºé–‹å§‹');
                  setIsVoiceDetected(true);
                },
                onSpeechEnd: async (audio) => {
                  console.log('éŸ³å£°æ¤œå‡ºçµ‚äº†');
                  setIsVoiceDetected(false);
                  
                  if (audio && audio.length > 0) {
                    console.log('VADéŸ³å£°ãƒ‡ãƒ¼ã‚¿è©³ç´°:', {
                      length: audio.length,
                      type: audio.constructor.name,
                      sampleRate: 16000,
                      duration: audio.length / 16000,
                      firstFewSamples: Array.from(audio.slice(0, 10)),
                      lastFewSamples: Array.from(audio.slice(-10))
                    });

                    const minDuration = 1.0;
                    const minSamples = minDuration * 16000;
                    
                    if (audio.length >= minSamples) {
                      try {
                        console.log('WAVå½¢å¼ã§å¤‰æ›ã‚’è©¦è¡Œ...');
                        const wavBlob = convertFloat32ArrayToWav(audio, 16000);
                        
                        console.log('WAV Blobè©³ç´°:', {
                          size: wavBlob.size,
                          type: wavBlob.type
                        });

                        setAudioBlob(wavBlob);
                        setAudioUrl(URL.createObjectURL(wavBlob));
                        console.log('WAVå½¢å¼ã§éŸ³å£°éŒ²éŸ³å®Œäº†:', audio.length, 'ã‚µãƒ³ãƒ—ãƒ«');
                        
                      } catch (wavError) {
                        console.error('WAVå¤‰æ›ã‚¨ãƒ©ãƒ¼:', wavError);
                        
                        try {
                          console.log('WebMå½¢å¼ã§å¤‰æ›ã‚’è©¦è¡Œ...');
                          const webmBlob = await convertFloat32ArrayToWebM(audio, 16000);
                          
                          console.log('WebM Blobè©³ç´°:', {
                            size: webmBlob.size,
                            type: webmBlob.type
                          });

                          setAudioBlob(webmBlob);
                          setAudioUrl(URL.createObjectURL(webmBlob));
                          console.log('WebMå½¢å¼ã§éŸ³å£°éŒ²éŸ³å®Œäº†:', audio.length, 'ã‚µãƒ³ãƒ—ãƒ«');
                          
                        } catch (webmError) {
                          console.error('WebMå¤‰æ›ã‚¨ãƒ©ãƒ¼:', webmError);
                          
                          console.log('ç”Ÿãƒ‡ãƒ¼ã‚¿å½¢å¼ã§ä¿å­˜...');
                          const fallbackBlob = new Blob([audio], { type: 'audio/raw' });
                          setAudioBlob(fallbackBlob);
                          setAudioUrl(URL.createObjectURL(fallbackBlob));
                          console.log('ç”Ÿãƒ‡ãƒ¼ã‚¿å½¢å¼ã§éŸ³å£°éŒ²éŸ³å®Œäº†:', audio.length, 'ã‚µãƒ³ãƒ—ãƒ«');
                        }
                      }
                    } else {
                      console.log('éŸ³å£°ãŒçŸ­ã™ãã¾ã™:', audio.length, 'ã‚µãƒ³ãƒ—ãƒ«');
                    }
                  }
                },
                onVADMisfire: () => {
                  console.log('VADèª¤æ¤œå‡º');
                  setIsVoiceDetected(false);
                },
                onFrameProcessed: (probabilities, frame) => {
                  console.log('VADç¢ºç‡:', probabilities);
                },
                minSpeechFrames: 5,
                frameSamples: 1024,
                positiveSpeechThreshold: 0.7,
                negativeSpeechThreshold: 0.3,
                redemptionFrames: 12,
                preSpeechPadFrames: 2
              });
              setVoiceDetectionStatus('ready');
            } catch (error) {
              console.error('VADå†åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼:', error);
              setVoiceDetectionStatus('error');
              return;
            }
          } else {
            setVoiceDetectionStatus('permission-denied');
            return;
          }
        } else {
          alert('ãƒã‚¤ã‚¯ã®æ¨©é™ãŒå¿…è¦ã§ã™ã€‚ãƒ–ãƒ©ã‚¦ã‚¶ã®è¨­å®šã§ãƒã‚¤ã‚¯ã®ä½¿ç”¨ã‚’è¨±å¯ã—ã¦ãã ã•ã„ã€‚');
          return;
        }
      } else if (voiceDetectionStatus !== 'ready') {
        alert('éŸ³å£°æ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ ã®æº–å‚™ãŒå®Œäº†ã—ã¦ã„ã¾ã›ã‚“ã€‚ã—ã°ã‚‰ãå¾…ã£ã¦ã‹ã‚‰å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚');
        return;
      }

      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
          sampleRate: 16000,
          // é¨’éŸ³ç’°å¢ƒå¯¾å¿œã®è¿½åŠ è¨­å®š
          channelCount: 1 // ãƒ¢ãƒãƒ©ãƒ«éŒ²éŸ³
        } 
      });
      
      streamRef.current = stream;

      // AudioContextè¨­å®šï¼ˆéŸ³é‡æ¸¬å®šç”¨ï¼‰
      let audioContext: AudioContext;
      if (audioContextRef.current && audioContextRef.current.state !== 'closed') {
        audioContext = audioContextRef.current;
      } else {
        audioContext = new (window.AudioContext || (window as any).webkitAudioContext)();
        audioContextRef.current = audioContext;
      }
      
      const source = audioContext.createMediaStreamSource(stream);
      const analyser = audioContext.createAnalyser();
      analyser.fftSize = 256;
      source.connect(analyser);
      analyserRef.current = analyser;

      // è‡ªå‹•éŸ³å£°æ¤œå‡ºã‚’é–‹å§‹
      if (voiceDetectionRef.current) {
        voiceDetectionRef.current.start();
        console.log('è‡ªå‹•éŸ³å£°æ¤œå‡ºéŒ²éŸ³é–‹å§‹');
      }

      setIsRecording(true);
      setIsPaused(false);
      setRecordingTime(0);
      setAudioBlob(null);
      setAudioUrl('');
      chunksRef.current = [];

      // ã‚¿ã‚¤ãƒãƒ¼é–‹å§‹
      timerRef.current = setInterval(() => {
        setRecordingTime(prev => {
          if (prev >= MAX_RECORDING_TIME) {
            stopRecording();
            return prev;
          }
          return prev + 1;
        });
      }, 1000);

      // éŸ³é‡æ¸¬å®šé–‹å§‹
      measureVolume();

    } catch (error) {
      console.error('VADéŒ²éŸ³é–‹å§‹ã‚¨ãƒ©ãƒ¼:', error);
      alert('éŒ²éŸ³ã‚’é–‹å§‹ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ãƒã‚¤ã‚¯ã®æ¨©é™ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚');
    }
      // eslint-disable-next-line react-hooks/exhaustive-deps
  }, [voiceDetectionStatus, measureVolume]);

  // è‡ªå‹•éŸ³å£°æ¤œå‡ºéŒ²éŸ³åœæ­¢
  const stopRecording = useCallback(async () => {
    // é€£ç¶šéŒ²éŸ³ãƒ¢ãƒ¼ãƒ‰ã‚’åœæ­¢
    await stopContinuousRecording();
    
    try {
      if (voiceDetectionRef.current) {
        voiceDetectionRef.current.pause();
        console.log('è‡ªå‹•éŸ³å£°æ¤œå‡ºéŒ²éŸ³åœæ­¢');
      }

      if (timerRef.current) {
        clearInterval(timerRef.current);
        timerRef.current = null;
      }

      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current);
        animationFrameRef.current = null;
      }

      if (streamRef.current) {
        streamRef.current.getTracks().forEach(track => track.stop());
        streamRef.current = null;
      }

      if (audioContextRef.current && audioContextRef.current.state !== 'closed') {
        try {
          await audioContextRef.current.close();
        } catch (error) {
          console.error('AudioContexté–‰ã˜ã‚‹ã‚¨ãƒ©ãƒ¼:', error);
        }
        audioContextRef.current = null;
      }

      setIsRecording(false);
      setIsPaused(false);
      setIsVoiceDetected(false);

    } catch (error) {
      console.error('VADéŒ²éŸ³åœæ­¢ã‚¨ãƒ©ãƒ¼:', error);
    }
  }, []);

  // éŒ²éŸ³ä¸€æ™‚åœæ­¢/å†é–‹
  const togglePause = useCallback(() => {
    if (isPaused) {
      setIsPaused(false);
      measureVolume();
    } else {
      setIsPaused(true);
      if (animationFrameRef.current) {
        cancelAnimationFrame(animationFrameRef.current);
        animationFrameRef.current = null;
      }
    }
  }, [isPaused, measureVolume]);

  // éŒ²éŸ³ãƒªã‚»ãƒƒãƒˆ
  const resetRecording = useCallback(() => {
    stopRecording();
    setRecordingTime(0);
    setAudioBlob(null);
    setAudioUrl('');
    setSoundName('');
    setIsVoiceDetected(false);
    setIsContinuousRecording(false);
    setAudioSegments([]);
    setRecordingStartTime(null);
  }, [stopRecording]);

    // éŸ³å£°ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
  const uploadAudio = useCallback(async () => {
    if (!audioBlob || !soundName.trim()) {
      alert('éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã‚µã‚¦ãƒ³ãƒ‰åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚');
      return;
    }

    setIsUploading(true);
    setUploadMessage('ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­...');

    try {
      const formData = new FormData();
      formData.append('file', audioBlob, `${soundName}.wav`);
      formData.append('name', soundName);

      const response = await axios.post('/api/kuu/sounds', formData, {
        headers: {
          'Content-Type': 'multipart/form-data',
        },
      });

      if (response.status === 200) {
        setUploadMessage('ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æˆåŠŸï¼');
        onUploadSuccess();
        resetRecording();
        
        // ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æˆåŠŸãƒ¢ãƒ¼ãƒ€ãƒ«è¡¨ç¤º
        showSuccessModal(
          'ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†',
          `ã€Œ${soundName}ã€ã®éŸ³å£°ãŒæ­£å¸¸ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã—ãŸï¼\nãã…ãƒ¼ï¼`
        );
      } else {
        setUploadMessage('ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸã€‚');
      }
    } catch (error: any) {
      console.error('ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼:', error);
      const errorMessage = error.response?.data?.message || 'ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸã€‚';
      setUploadMessage(errorMessage);
    } finally {
      setIsUploading(false);
    }
  }, [audioBlob, soundName, onUploadSuccess, resetRecording, showSuccessModal]);

  // éŸ³å£°å‰Šé™¤
  const deleteAudio = useCallback(async (soundId: string) => {
    try {
      const response = await axios.delete(`/api/kuu/sounds/${soundId}`);
      
      if (response.status === 200) {
        // å‰Šé™¤æˆåŠŸãƒ¢ãƒ¼ãƒ€ãƒ«è¡¨ç¤º
        showSuccessModal(
          'å‰Šé™¤å®Œäº†',
          'éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ­£å¸¸ã«å‰Šé™¤ã•ã‚Œã¾ã—ãŸï¼'
        );
        onUploadSuccess(); // ãƒªã‚¹ãƒˆã‚’æ›´æ–°
      } else {
        alert('å‰Šé™¤ã«å¤±æ•—ã—ã¾ã—ãŸã€‚');
      }
    } catch (error: any) {
      console.error('å‰Šé™¤ã‚¨ãƒ©ãƒ¼:', error);
      const errorMessage = error.response?.data?.message || 'å‰Šé™¤ã«å¤±æ•—ã—ã¾ã—ãŸã€‚';
      alert(errorMessage);
    }
  }, [showSuccessModal, onUploadSuccess]);

  // æ™‚é–“ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
  const formatTime = (seconds: number) => {
    const mins = Math.floor(seconds / 60);
    const secs = seconds % 60;
    return `${mins.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`;
  };

  if (isSupported === false) {
    return (
      <div className="max-w-md mx-auto p-6 bg-white rounded-lg shadow-lg">
        <div className="text-center text-red-600">
          <p>ã“ã®ãƒ–ãƒ©ã‚¦ã‚¶ã¯éŒ²éŸ³æ©Ÿèƒ½ã«å¯¾å¿œã—ã¦ã„ã¾ã›ã‚“ã€‚</p>
          <p>Chromeã€Firefoxã€Safariã®æœ€æ–°ç‰ˆã‚’ã”åˆ©ç”¨ãã ã•ã„ã€‚</p>
        </div>
      </div>
    );
  }

  return (
    <div className="max-w-md mx-auto p-6 bg-white rounded-lg shadow-lg">
      <h2 className="text-2xl font-bold text-center mb-6 text-gray-800">
        éŸ³å£°éŒ²éŸ³ï¼ˆè‡ªå‹•éŸ³å£°æ¤œå‡ºå¯¾å¿œï¼‰
      </h2>

      {/* éŸ³å£°æ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤º */}
      <div className="mb-4 p-3 rounded-lg bg-blue-50">
        <div className="text-sm text-gray-600">
          <div className="flex items-center justify-between">
            <span>éŸ³å£°æ¤œå‡ºã‚·ã‚¹ãƒ†ãƒ :</span>
            <span className={`font-medium ${
              voiceDetectionStatus === 'ready' ? 'text-green-600' :
              voiceDetectionStatus === 'loading' ? 'text-yellow-600' :
              voiceDetectionStatus === 'error' ? 'text-red-600' :
              voiceDetectionStatus === 'permission-denied' ? 'text-red-600' : 'text-gray-600'
            }`}>
              {voiceDetectionStatus === 'ready' ? 'æº–å‚™å®Œäº†' :
               voiceDetectionStatus === 'loading' ? 'åˆæœŸåŒ–ä¸­...' :
               voiceDetectionStatus === 'error' ? 'ã‚¨ãƒ©ãƒ¼' :
               voiceDetectionStatus === 'permission-denied' ? 'æ¨©é™æ‹’å¦' : 'å¾…æ©Ÿä¸­'}
            </span>
          </div>
          
          {/* éŸ³å£°æ¤œå‡ºã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼ */}
          {isRecording && (
            <div className="mt-2 flex items-center">
              <span className="text-sm text-gray-600 mr-2">éŸ³å£°æ¤œå‡º:</span>
              <div className={`w-3 h-3 rounded-full ${
                isVoiceDetected ? 'bg-green-500 animate-pulse' : 'bg-gray-300'
              }`}></div>
              <span className="text-sm text-gray-600 ml-2">
                {isVoiceDetected ? 'æ¤œå‡ºä¸­' : 'å¾…æ©Ÿä¸­'}
              </span>
            </div>
          )}
          
          {/* é€£ç¶šéŒ²éŸ³ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼ */}
          {isContinuousRecording && (
            <div className="mt-2 flex items-center">
              <span className="text-sm text-gray-600 mr-2">é€£ç¶šéŒ²éŸ³:</span>
              <div className="w-3 h-3 rounded-full bg-blue-500 animate-pulse"></div>
              <span className="text-sm text-gray-600 ml-2">
                {audioSegments.length}ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ ({recordingStartTime ? Math.round((Date.now() - recordingStartTime) / 1000) : 0}ç§’)
              </span>
            </div>
          )}
        </div>
      </div>

      {/* éŒ²éŸ³æ™‚é–“è¡¨ç¤º */}
      <div className="text-center mb-4">
        <div className="text-3xl font-mono text-gray-800">
          {formatTime(recordingTime)}
        </div>
        <div className="text-sm text-gray-600">
          {recordingTime >= MAX_RECORDING_TIME ? 'æœ€å¤§éŒ²éŸ³æ™‚é–“ã«é”ã—ã¾ã—ãŸ' : 'æœ€å¤§30ç§’'}
        </div>
      </div>

      {/* éŸ³é‡ãƒ¬ãƒ™ãƒ«è¡¨ç¤º */}
      {isRecording && !isPaused && (
        <div className="mb-4">
          <div className="flex items-center justify-between text-sm text-gray-600 mb-1">
            <span>éŸ³é‡ãƒ¬ãƒ™ãƒ«</span>
            <span>{Math.round(volumeLevel)}%</span>
          </div>
          <div className="w-full bg-gray-200 rounded-full h-2">
            <div
              className="bg-blue-500 h-2 rounded-full transition-all duration-100"
              style={{ width: `${Math.min(volumeLevel, 100)}%` }}
            ></div>
          </div>
        </div>
      )}

      {/* éŒ²éŸ³ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ« */}
      {!audioUrl && (
        <div className="flex justify-center space-x-4 mb-6">
          {!isRecording ? (
            <button
              onClick={startRecording}
              disabled={voiceDetectionStatus !== 'ready' && voiceDetectionStatus !== 'permission-denied'}
              className={`px-6 py-3 rounded-lg font-medium transition-colors ${
                voiceDetectionStatus === 'ready'
                  ? 'bg-red-500 hover:bg-red-600 text-white'
                  : voiceDetectionStatus === 'permission-denied'
                  ? 'bg-orange-500 hover:bg-orange-600 text-white'
                  : 'bg-gray-300 text-gray-500 cursor-not-allowed'
              }`}
            >
              {voiceDetectionStatus === 'permission-denied' ? 'æ¨©é™ã‚’è¨±å¯ã—ã¦éŒ²éŸ³é–‹å§‹' : 'éŒ²éŸ³é–‹å§‹'}
            </button>
          ) : (
            <>
              <button
                onClick={togglePause}
                className="px-6 py-3 rounded-lg font-medium bg-yellow-500 hover:bg-yellow-600 text-white transition-colors"
              >
                {isPaused ? 'å†é–‹' : 'ä¸€æ™‚åœæ­¢'}
              </button>
              <button
                onClick={stopRecording}
                className="px-6 py-3 rounded-lg font-medium bg-red-500 hover:bg-red-600 text-white transition-colors"
              >
                éŒ²éŸ³åœæ­¢
              </button>
            </>
          )}
        </div>
      )}

      {/* éŒ²éŸ³çµæœè¡¨ç¤º */}
      {audioUrl && (
        <div className="mb-6">
          <h3 className="text-lg font-semibold mb-3 text-gray-800">éŒ²éŸ³çµæœ</h3>
          <audio controls className="w-full mb-4">
            <source src={audioUrl} type={audioBlob?.type || 'audio/wav'} />
            ãŠä½¿ã„ã®ãƒ–ãƒ©ã‚¦ã‚¶ã¯éŸ³å£°å†ç”Ÿã«å¯¾å¿œã—ã¦ã„ã¾ã›ã‚“ã€‚
          </audio>
          

          
          <div className="mb-4">
            <label htmlFor="soundName" className="block text-sm font-medium text-gray-700 mb-2">
              ã‚µã‚¦ãƒ³ãƒ‰å
            </label>
            <input
              type="text"
              id="soundName"
              value={soundName}
              onChange={(e) => setSoundName(e.target.value)}
              placeholder="ã‚µã‚¦ãƒ³ãƒ‰åã‚’å…¥åŠ›"
              className="w-full px-3 py-2 border border-gray-300 rounded-lg focus:outline-none focus:ring-2 focus:ring-blue-500"
            />
          </div>

          <div className="flex space-x-3">
            <button
              onClick={uploadAudio}
              disabled={isUploading || !soundName.trim()}
              className={`flex-1 px-4 py-2 rounded-lg font-medium transition-colors ${
                isUploading || !soundName.trim()
                  ? 'bg-gray-300 text-gray-500 cursor-not-allowed'
                  : 'bg-green-500 hover:bg-green-600 text-white'
              }`}
            >
              {isUploading ? 'ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­...' : 'ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰'}
            </button>
            <button
              onClick={resetRecording}
              className="px-4 py-2 rounded-lg font-medium bg-gray-500 hover:bg-gray-600 text-white transition-colors"
            >
              ãƒªã‚»ãƒƒãƒˆ
            </button>
          </div>

          {uploadMessage && (
            <div className={`mt-3 p-3 rounded-lg text-sm ${
              uploadMessage.includes('æˆåŠŸ') 
                ? 'bg-green-100 text-green-800' 
                : 'bg-red-100 text-red-800'
            }`}>
              {uploadMessage}
            </div>
          )}
        </div>
      )}

      {/* ä½¿ç”¨æ–¹æ³•èª¬æ˜ */}
      <div className="mt-6 p-4 bg-blue-50 rounded-lg">
        <h4 className="font-semibold text-blue-800 mb-2">ä½¿ç”¨æ–¹æ³•</h4>
        <ul className="text-sm text-blue-700 space-y-1">
          <li>â€¢ <strong>é€£ç¶šéŒ²éŸ³ãƒ¢ãƒ¼ãƒ‰</strong>: é•·ã„éŸ³å£°ã‚’é€”åˆ‡ã‚Œã‚‹ã“ã¨ãªãéŒ²éŸ³</li>
          <li>â€¢ éŸ³å£°ãŒæ¤œå‡ºã•ã‚Œã‚‹ã¨è‡ªå‹•çš„ã«éŒ²éŸ³ãŒé–‹å§‹ã•ã‚Œã¾ã™</li>
          <li>â€¢ éŸ³å£°ãŒçµ‚äº†ã—ã¦ã‚‚éŒ²éŸ³ã¯ç¶™ç¶šã•ã‚Œã€æ¬¡ã®éŸ³å£°ã‚’å¾…æ©Ÿã—ã¾ã™</li>
          <li>â€¢ éŒ²éŸ³åœæ­¢ãƒœã‚¿ãƒ³ã§å…¨ã¦ã®éŸ³å£°ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’çµåˆã—ã¦ä¿å­˜</li>
          <li>â€¢ ç„¡éŸ³éƒ¨åˆ†ã¯è‡ªå‹•çš„ã«é™¤å»ã•ã‚Œã€è‡ªç„¶ãªéŸ³å£°ã«ãªã‚Šã¾ã™</li>
          <li>â€¢ æœ€å¤§30ç§’ã¾ã§éŒ²éŸ³å¯èƒ½</li>
        </ul>
        
        <div className="mt-4 p-3 bg-yellow-50 rounded-lg border-l-4 border-yellow-400">
          <h5 className="font-semibold text-yellow-800 mb-2">é¨’éŸ³ç’°å¢ƒã§ã®ä½¿ç”¨</h5>
          <ul className="text-sm text-yellow-700 space-y-1">
            <li>â€¢ é¨’éŸ³ç’°å¢ƒã§ã¯1ç§’ä»¥ä¸Šã®éŸ³å£°ãŒå¿…è¦ã§ã™</li>
            <li>â€¢ èƒŒæ™¯éŸ³ãŒå¤§ãã„å ´åˆã¯ã€ãƒã‚¤ã‚¯ã«è¿‘ã¥ã„ã¦è©±ã—ã¦ãã ã•ã„</li>
            <li>â€¢ çŸ­ã„éŸ³å£°ã‚„èƒŒæ™¯éŸ³ã¯è‡ªå‹•çš„ã«é™¤å¤–ã•ã‚Œã¾ã™</li>
            <li>â€¢ éŸ³å£°æ¤œå‡ºã®æ„Ÿåº¦ã‚’èª¿æ•´æ¸ˆã¿ï¼ˆé¨’éŸ³å¯¾å¿œï¼‰</li>
          </ul>
        </div>
        
        {voiceDetectionStatus === 'permission-denied' && (
          <div className="mt-4 p-3 bg-red-50 rounded-lg border-l-4 border-red-400">
            <h5 className="font-semibold text-red-800 mb-2">ãƒã‚¤ã‚¯æ¨©é™ã«ã¤ã„ã¦</h5>
            <ul className="text-sm text-red-700 space-y-1">
              <li>â€¢ ãƒã‚¤ã‚¯ã®ä½¿ç”¨ãŒæ‹’å¦ã•ã‚Œã¦ã„ã¾ã™</li>
              <li>â€¢ ãƒ–ãƒ©ã‚¦ã‚¶ã®è¨­å®šã§ãƒã‚¤ã‚¯ã®ä½¿ç”¨ã‚’è¨±å¯ã—ã¦ãã ã•ã„</li>
              <li>â€¢ ã‚¢ãƒ‰ãƒ¬ã‚¹ãƒãƒ¼ã®ğŸ”’ã‚¢ã‚¤ã‚³ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦æ¨©é™ã‚’ç¢ºèª</li>
              <li>â€¢ ã€Œæ¨©é™ã‚’è¨±å¯ã—ã¦éŒ²éŸ³é–‹å§‹ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦å†è©¦è¡Œ</li>
            </ul>
          </div>
        )}
      </div>

      {/* ãƒ¢ãƒ¼ãƒ€ãƒ« */}
      <Modal
        show={showModal}
        title={modalTitle}
        message={modalMessage}
        onClose={closeModal}
        showKuuEffect={modalType === 'success'}
      />
    </div>
  );
} 